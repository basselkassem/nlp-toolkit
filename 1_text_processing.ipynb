{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-text-processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQbl2iI2x+5iAXUAM28qAl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basselkassem/nlp-toolkit/blob/master/1_text_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDe1cLh8Iz6j",
        "colab_type": "text"
      },
      "source": [
        "**A text is a sequence of:**\n",
        "\n",
        "\n",
        "1. characters\n",
        "2. words\n",
        "3. sentences\n",
        "4. paragraphs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DTQvgGRt6Zm",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHNfzSqdqZA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTfc8Gxqqh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"I am hungry, I cann't find food.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAdhV82Wrc6n",
        "colab_type": "code",
        "outputId": "c049117a-3767-489b-80fb-84ce579853bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ws_tokenizer = WhitespaceTokenizer()\n",
        "print(ws_tokenizer.tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'am', 'hungry,', 'I', \"cann't\", 'find', 'food.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyBsaNAlr47P",
        "colab_type": "code",
        "outputId": "2f9d6d1c-c5f3-46bd-983e-e55e8094ea07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wp_tokenizer = WordPunctTokenizer()\n",
        "print(wp_tokenizer.tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'am', 'hungry', ',', 'I', 'cann', \"'\", 't', 'find', 'food', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx3vwfcPsMHW",
        "colab_type": "code",
        "outputId": "837c7498-4599-4741-f9e5-68246ede3813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tbw_tokenizer = TreebankWordTokenizer()\n",
        "print(tbw_tokenizer.tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'am', 'hungry', ',', 'I', 'can', \"n't\", 'find', 'food', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3FvQMlI3tYM",
        "colab_type": "text"
      },
      "source": [
        "# Normalization\n",
        "1. stemming\n",
        "2. lemmatization\n",
        "\n",
        "try both and choose the one that give best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sweBgrVQ6WM-",
        "colab_type": "code",
        "outputId": "c2c6aa44-5597-44ac-fd9b-ca2076cc6ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YdJrbP047Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw5lGvZv6RZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"playing was missunderstands extractions dogs stations beautiful limitations called understood\"\n",
        "tokens = tbw_tokenizer.tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brwN-xJo3x1s",
        "colab_type": "code",
        "outputId": "50035244-c069-4e59-ae91-4a34e0f6c569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "res = [stemmer.stem(token) for token in tokens]\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['play', 'wa', 'missunderstand', 'extract', 'dog', 'station', 'beauti', 'limit', 'call', 'understood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpzcTO06Bs8",
        "colab_type": "code",
        "outputId": "26777de4-033f-4a53-abb1-f233bb11c325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stemmer = WordNetLemmatizer()\n",
        "res = [stemmer.lemmatize(token) for token in tokens]\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['playing', 'wa', 'missunderstands', 'extraction', 'dog', 'station', 'beautiful', 'limitation', 'called', 'understood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fktJQ-QQ8wP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stanfordnlp\n",
        "#stanfordnlp.download('en', force=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TUces4v92MS",
        "colab_type": "code",
        "outputId": "03c87dc0-b93a-4057-a312-c3e12a3bbc1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "stemmer = stanfordnlp.Pipeline(lang = 'en', processors='tokenize,lemma', use_gpu=False)\n",
        "doc = stemmer(text)\n",
        "for i, sentence in enumerate(doc.sentences):\n",
        "  for word in sentence.words:\n",
        "    print(word.text, word.lemma)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "Done loading processors!\n",
            "---\n",
            "playing play\n",
            "was be\n",
            "missunderstands missunderstand\n",
            "extractions extraction\n",
            "dogs dog\n",
            "stations station\n",
            "beautiful beautiful\n",
            "limitations limitation\n",
            "called call\n",
            "understood understand\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5jcctfUuB5x",
        "colab_type": "text"
      },
      "source": [
        "# Vectorization (feature extraction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwGTL5O-tD_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFH-m35Iua-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [\n",
        "          \"good movie\",\n",
        "          \"not a good movie\",\n",
        "          \"did not like\",\n",
        "          \"I like it\",\n",
        "          \"good one\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmh7ndxVKIz3",
        "colab_type": "text"
      },
      "source": [
        "## Bag of words\n",
        "Count the occurrences of a token/n-gram in a text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzzQMn7tv6Ld",
        "colab_type": "code",
        "outputId": "fb1679af-db64-42a7-d070-4351d05b1e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "count_vectorizer = CountVectorizer(ngram_range=[1, 2], min_df=2, max_df=0.5)\n",
        "x = count_vectorizer.fit_transform(corpus)\n",
        "cols = count_vectorizer.get_feature_names()\n",
        "rows = x.toarray()\n",
        "features = pd.DataFrame(columns=cols, data = rows)\n",
        "print(features.shape)\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good movie</th>\n",
              "      <th>like</th>\n",
              "      <th>movie</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   good movie  like  movie  not\n",
              "0           1     0      1    0\n",
              "1           1     0      1    1\n",
              "2           0     1      0    1\n",
              "3           0     1      0    0\n",
              "4           0     0      0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg_ugjKzKWMJ",
        "colab_type": "text"
      },
      "source": [
        "## Tfidf (term frequency inverse document frequency)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsLp1-1fLG9s",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "**$idf$**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*   $N = |D|$ total number of documents\n",
        "*   $|\\{d \\in D: t\\in d\\}|$ number of documents where term $t$ appears\n",
        "*   $idf(t, D) = log(\\frac{N}{|\\{d \\in D: t\\in d\\}|})$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**$tfidf$**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*   $tf(t,d)= \\Bigg\\{\\begin{array}\\frac{f_{t,d}}{\\sum_w f_{w,d}}\\\\1 + log(f_{t,d})\\end{array}$\n",
        "*   $tfidf(t,d,D)=tf(t,d) \\times idf(t, D)$\n",
        "*  Terms which appeare frequently in small number of documents will get high $tfidf$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLYDAkfYyNjF",
        "colab_type": "code",
        "outputId": "46a693c8-bf78-41bb-8867-01a11edcfb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tfidf_tokenizer = TfidfVectorizer(ngram_range = (1, 2), min_df= 2, max_df=2)\n",
        "x = tfidf_tokenizer.fit_transform(corpus)\n",
        "cols = tfidf_tokenizer.get_feature_names()\n",
        "rows = x.todense()\n",
        "features = pd.DataFrame(columns=cols, data = rows)\n",
        "print(features.shape)\n",
        "features\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good movie</th>\n",
              "      <th>like</th>\n",
              "      <th>movie</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.577350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   good movie      like     movie       not\n",
              "0    0.707107  0.000000  0.707107  0.000000\n",
              "1    0.577350  0.000000  0.577350  0.577350\n",
              "2    0.000000  0.707107  0.000000  0.707107\n",
              "3    0.000000  1.000000  0.000000  0.000000\n",
              "4    0.000000  0.000000  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK0IDQ5eygig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
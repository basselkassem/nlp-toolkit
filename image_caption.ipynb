{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-caption",
      "provenance": [],
      "collapsed_sections": [
        "5VTxZsFMoaGP",
        "7F1hTw5SrwMD",
        "NLIXER9z6VaD",
        "juwXvj7eUr1C",
        "FSGG8PB9UsJN"
      ],
      "authorship_tag": "ABX9TyMdsK7CIp0d8Q7NWxpeDHyu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basselkassem/nlp-toolkit/blob/master/image_caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VTxZsFMoaGP",
        "colab_type": "text"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbWMgv_HKxie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f0852d2b-9bf8-4c83-88f8-91827cafb3af"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-08 23:27:08--  http://images.cocodataset.org/zips/train2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.176.91\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.176.91|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/zip]\n",
            "Saving to: ‘train2014.zip’\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  16.8MB/s    in 13m 7s  \n",
            "\n",
            "2020-08-08 23:40:15 (16.4 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8w8HCAtqEIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0170c715-3bb7-4f0b-c2f3-7d9ef74d49e1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations_trainval2014.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdSVdG3eqoXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1c563813-64b0-464b-ae2a-1c0100908f62"
      },
      "source": [
        "%%time\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('train2014.zip') as ref_file:\n",
        "  ref_file.extractall()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 33.3 s, sys: 26.5 s, total: 59.8 s\n",
            "Wall time: 4min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XF-qbuWpS87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b7b6b7ab-624d-4d34-eb27-ea2712c993cf"
      },
      "source": [
        "%%time\n",
        "with ZipFile('annotations_trainval2014.zip') as ref_file:\n",
        "  ref_file.extractall()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.98 s, sys: 1.19 s, total: 7.17 s\n",
            "Wall time: 7.35 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzCWC7Uur7tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c0650838-1a58-4e2c-fec7-608ec3300efc"
      },
      "source": [
        "!ls annotations"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "captions_train2014.json   instances_val2014.json\n",
            "captions_val2014.json\t  person_keypoints_train2014.json\n",
            "instances_train2014.json  person_keypoints_val2014.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1BjWBJIoeJ6",
        "colab_type": "text"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAdz4SH3ogRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uTJVdbmtOCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2GCZVUarzQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dd3e6e8-f7d2-411b-9891-6ca1bc8cd0d8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Dense, Embedding, GRU, Flatten\n",
        "from tensorflow.keras.applications import InceptionV3, inception_v3\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F1hTw5SrwMD",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4SbGSiGrvPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_folder = 'train2014/'\n",
        "annotation_file = 'annotations/captions_train2014.json'\n",
        "\n",
        "with open(annotation_file) as ref_file:\n",
        "  annotations = json.load(ref_file)\n",
        "annotations = annotations['annotations']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GgLreLc5bcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAMPLES_NUM = 100\n",
        "captions_list = np.random.choice(annotations, size = SAMPLES_NUM)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZn1BdWz1lyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_img_name(img_id):\n",
        "  return 'COCO_train2014_{:012d}.jpg'.format(img_id)\n",
        "\n",
        "captions, image_paths = [], []\n",
        "for caption_item in captions_list:\n",
        "  img_path = image_folder + get_img_name(caption_item['image_id'])\n",
        "  image_paths.append(img_path)\n",
        "  captions.append(caption_item['caption'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLIXER9z6VaD",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juwXvj7eUr1C",
        "colab_type": "text"
      },
      "source": [
        "## Image Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD9Ki6pKU9mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_image(img):\n",
        "  res_img = tf.image.resize(img, size =(299, 299))\n",
        "  return inception_v3.preprocess_input(res_img)\n",
        "\n",
        "def read_image(img_path):\n",
        "  img = tf.io.read_file(img_path)\n",
        "  img = tf.image.decode_jpeg(img, channels = 3)\n",
        "  return process_image(img), img_path\n",
        "\n",
        "def create_feature_extractor():\n",
        "  model = InceptionV3(include_top=False, weights = 'imagenet')\n",
        "  input = model.input\n",
        "  output = model.layers[-1].output\n",
        "  feature_extractor = Model(inputs = input, outputs = output)\n",
        "  return feature_extractor\n",
        "\n",
        "feature_extractor = create_feature_extractor()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvQw6DEnfmsy",
        "colab_type": "text"
      },
      "source": [
        "Load the images, extract features using inception_v3 and save the results on the desk. The reasons of doing this are: \n",
        "*  Use tensorflow parallel computing abilities to load the images\n",
        "*  Reduce the amount of computations required during training by extracting features from images at early stage\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbqNxfZSgnWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_image_paths = sorted(set(image_paths))\n",
        "image_ds = tf.data.Dataset.from_tensor_slices(unique_image_paths)\n",
        "image_ds = image_ds.map(\n",
        "    read_image, num_parallel_calls = tf.data.experimental.AUTOTUNE\n",
        ").batch(32)\n",
        "\n",
        "for imgs_batch, path_batch in image_ds:\n",
        "  img_features_batch = feature_extractor(imgs_batch)\n",
        "  img_features_batch = tf.reshape(img_features_batch, shape = (\n",
        "      img_features_batch.shape[0], img_features_batch.shape[1] * img_features_batch.shape[2], -1,\n",
        "  ))\n",
        "\n",
        "  for img_features, path in zip(img_features_batch, path_batch):\n",
        "    img_path = path.numpy().decode('utf-8')\n",
        "    np.save(img_path, img_features)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSGG8PB9UsJN",
        "colab_type": "text"
      },
      "source": [
        "##Caption Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO9tqZIZ6Umr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_num = 5000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words = words_num,\n",
        "    filters = '!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ',\n",
        "    oov_token = '<unk>',\n",
        ")\n",
        "tokenizer.fit_on_texts(captions)\n",
        "tokenizer.word_index['<pad>'] = 0\n",
        "tokenizer.index_word[0] = '<pad>'\n",
        "\n",
        "captions_seqs = tokenizer.texts_to_sequences(captions)\n",
        "captions_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    captions_seqs, \n",
        "    padding = 'post',\n",
        ")"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRxoXRWxs6DH",
        "colab_type": "text"
      },
      "source": [
        "## Creating Train/Test Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e4vNKIgtLdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b2c5660-14e0-49fa-c664-e3a14481c6eb"
      },
      "source": [
        "img_paths_tr, img_paths_val, captions_seqs_tr, captions_seqs_val = train_test_split(\n",
        "    image_paths, captions_seqs, train_size = 0.8,\n",
        ")\n",
        "len(img_paths_tr), len(img_paths_val), len(captions_seqs_tr), len(captions_seqs_val)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 20, 80, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY0RL3w3sYA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = words_num + 1\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "def load_img_features(img_path, caption):\n",
        "  path = img_path.decode('utf-8') + '.npy'\n",
        "  return np.load(path), caption\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((img_paths_tr, captions_seqs_tr))\n",
        "train_ds = train_ds.map(\n",
        "    lambda img_path, caption: tf.numpy_function(\n",
        "      load_img_features,  [img_path, caption], [tf.float32, tf.int32],  \n",
        "    ),\n",
        "    num_parallel_calls = tf.data.experimental.AUTOTUNE,\n",
        ")\n",
        "\n",
        "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_ds = train_ds.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZdyQNy9vwL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11f1274b-e698-478b-8270-612ade9a18ce"
      },
      "source": [
        "sample_img_batch, sample_cap_batch = next(iter(train_ds))\n",
        "sample_img_batch.shape, sample_cap_batch.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 64, 2048]), TensorShape([64, 45]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC6jZSPsyjUd",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnymL19pz5yV",
        "colab_type": "text"
      },
      "source": [
        "## Attention Mechanisim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O8z_79D0Xzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(Model):\n",
        "  def __init__(self, units):\n",
        "    super(Attention, self).__init__()\n",
        "    pass\n",
        "  def call(seld, features, states):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oStmcxPzuM7",
        "colab_type": "text"
      },
      "source": [
        "## CNN Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "insrTyAF-m7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNEncoder(Model):\n",
        "  def __init__(self):\n",
        "    super(CNNEncoder, self).__init__()\n",
        "  def call(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4xUjcREzk9S",
        "colab_type": "text"
      },
      "source": [
        "## RNN Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHxc0Njx0Yeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNDecoder(Model):\n",
        "  def __init__(self):\n",
        "    super(RNNDecoder, self).__init__()\n",
        "  def call(self, ):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUgVLPuU0Pd_",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR4mYvcs_d6X",
        "colab_type": "text"
      },
      "source": [
        "## Checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzeyBvSJ0EG0",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR0O79qr0IDm",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dzkv7bIySX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}